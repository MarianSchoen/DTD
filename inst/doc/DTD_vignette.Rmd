---
  title: "Loss-function learning for digital tissue deconvolution"
  author: "Marian SchÃ¶n"
  date: "`r Sys.Date()`"
  output: 
    rmarkdown::html_vignette: 
      toc: TRUE
  bibliography: bibliography.bib
  vignette: >
    %\VignetteIndexEntry{Vignette Title}
    %\VignetteEngine{knitr::rmarkdown}
    %\VignetteEncoding{UTF-8}
---
```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r include=FALSE}
  # for fast testing 
  maxit <- 250
  nSamples <- 500
```

# What is DTD?
The gene expression profile of a tissue averages the expression profiles of all cells in this tissue. Digital tissue deconvolution (DTD) addresses the following inverse problem: Given the expression profile __y__ of a tissue, what is the cellular composition __c__ of that tissue? The theory and mathematical background of a DTD model that uses 
loss-function learning has been published by @Goertler2018. With this package we provide all necessary R functions and routines to train and use a loss-function learning digital tissue deconvolution model. 

The article uses the following notation. The 'reference matrix' is denoted as X. Every column $X_{.,k}$ is a cellular reference profile. The expression matrix of 'bulk profiles' is named Y. Every column $Y_{.,k}$ is a mixtures of cells, for which the quantities of the given cell profiles in X should be estimated. 
The standard deconvolution formula is given by 
\begin{equation}
  arg~ min_c ~|| Y_{.,k} - Xc||
\end{equation}
@Goertler2018 improve this formula by introducing a vector __g__ 
\begin{equation}
  arg~ min_c ~|| diag(g) (Y_{.,k} - Xc)||
\end{equation}
Every entry $g_i$ of g holds the information how important gene i is for the deconvolution process. The underlying idea of loss-function learning DTD is to gain the vector g by minimizing a loss function L on a training set. 
\begin{equation}
  L = - \sum_{j=1}^g cor(C_{j,.}, \widehat{C_{j,.}} (g))
\end{equation}
The training set consists of a matrix Y with bulk profiles, for which the quantities of the cells in X should be estimated. Additionally there is a matrix C. In the composition or quantity matrix C every column $C_{.,k}$ holds the distribution of the reference cells X in the bulk profile $Y_{.,k}$. For the loss function L the correlation between the known quantities $C_{j,.}$ and the estimated quantities $\widehat{C_{j,.}}(g)$ is calculated per reference profile j. 

In the package DTD we provide functions to generate a training and test set, and a FISTA implementation to minimize the loss function iteratively. 

# How to use? 
In the following examples, we demonstrate how data has to look like in order to be used for loss-function learning digital tissue deconvolution. After that, we give examples on how to process the data, how to generate a test and training set, how to train the g vector, and finally, how to visualize the result. 
First of all, load the library: 
```{r}
  library(DTD)
```
## Data generation
The DTD package needs expression measurements of sorted cells to train a g-vector. We did not include any data in the DTD package. In order to demonstrate all functions, and to show users how the data needs to be processed, we included a `generate.random.data` function.
Basically, this function has 3 key arguments:

- nTypes: integer, how many different types should be included in the data set. 
- nSamples.perType: integer, how many samples should be generated per type.
- nFeatures: integer, how many features should be included.

In the following we generate data consisting of 10 different cell types, with 500 features. For each cell type we generate 100 samples. 
```{r}
  number.types <- 10
  random.data <- generate.random.data(nTypes = number.types, 
                                      nSamples.perType = 150, 
                                      nFeatures = 250)
```
The object `random.data` is a numeric matrix with `r nrow(random.data)` rows (features), and `r ncol(random.data)` columns (samples).
```{r}
  print(random.data[1:5, 1:5])
  
  # for further exemplary visualization 
  example.index <- c(1, 151, 301, 451)
```
 Notice that the colnames of `random.data` indicate the type of cell:
```{r}
  print(colnames(random.data)[example.index])
```

Now the generated expression matrix `random.data` looks similar to expression measurements published by @Tirosh2016 OR DO I HAVE ANY OTHER EXAMPLE. (Human cell atlas?)

## Data processing
The first step in processing the raw expression matrix is to undo log transformation. This is necessary because our DTD approach works on an additive scale, not a multiplicative. 
In our case data is log2 transformed, therefore
```{r}
    random.data <- 2^random.data - 1
```
Next, we scale every sample of the data set to a fix number of counts. Using the provided `normalizeToCount` function, every sample gets scaled such that the sum over all counts equals $10^6$:
```{r}
  # In random.data the number of counts differs over all samples: 
  apply(random.data, 2, sum)[example.index]
  normalized.data <- normalizeToCount(random.data)
  # In normalized.data all samples share the same number of counts: 
  apply(normalized.data, 2, sum)[example.index]
```

In addition to the normalized data matrix the DTD algorithm needs a `indicator.list`:
```{r}
 indicator.list <- gsub("^Cell[0-9]*\\.", "", colnames(normalized.data))
 names(indicator.list) <- colnames(normalized.data)
 print(indicator.list[example.index])
```
`indicator.list` needs to be a named list. Each entry assigns the cell type (as value of the list) to every sample (names of the list) in the `normalized.data`. 

## Reference matrix X

 Next, we select the reference matrix X. In our data set there are `r number.types` different cell types. In this example we do not distinguish between all of them. The types we want to deconvolute are: 
```{r}
  include.in.X <- paste0("Type", 2:7)
  print(include.in.X)
```
For each of these types we need a reference profile $X_{.,k}$:
```{r}
  X.matrix <- matrix(NA, nrow=nrow(normalized.data), ncol=length(include.in.X))
  colnames(X.matrix) <- include.in.X
  rownames(X.matrix) <- rownames(normalized.data)
```
For each cell type its reference profile will be calculated as the average over a fraction of all samples in the whole data set:
```{r}
  percentage.of.all.cells <- 0.2
  samples.to.remove <- c()
  for(l.type in include.in.X){
    # get sample names of all cells of type "l.type" 
    all.of.type <- names(indicator.list)[which(indicator.list == l.type)]
    
    # randomly sample some cells
    chosen.for.X <- sample(x = all.of.type,
                           size = ceiling(length(all.of.type) * percentage.of.all.cells),
                           replace = FALSE)
    
    # Add those cells which will be included in X to the list of samples.to.remove 
    samples.to.remove <- c(samples.to.remove, chosen.for.X)

    # for each gene average over the selected 
    average <- rowSums(normalized.data[, chosen.for.X, drop = FALSE])
    X.matrix[, l.type] <- average
 }
```
Notice that every sample which has been used in the reference matrix X must not be included in the training or test set! In order to keep track of samples which must not be used furthermore we introduced the variable `samples.to.remove`. We remove all samples that have been used for generating X, and split the remaining samples into a training and a test set.
```{r}
  remaining.mat <- normalized.data[, -which(colnames(normalized.data) %in% samples.to.remove)]
  train.samples <- sample(x = colnames(remaining.mat), 
                          size = ceiling(ncol(remaining.mat)/2), 
                          replace = FALSE)
  test.samples <- colnames(remaining.mat)[which(!colnames(remaining.mat) %in% train.samples)]
  
  train.mat <- remaining.mat[, train.samples]
  test.mat <- remaining.mat[, test.samples]
```


## Mixing training and test set

The loss-function learning DTD algorithm trains a g-vector on a trainig set. Basically, the training set is a list of two matrices. 

- Y, or mixtures matrix. Y has as many rows (=features) as `X.matrix` or `normalized.data`. Every column y of Y is a mixture of the cells in the data set.
- C, or quantities matrix. C has as many rows as there are cells in `X.matrix`. Every column of C holds the distribution of the cells in each mixture of Y. 

In this package we provide two methods to generate the training set. One method randomly samples many cells of the complete data set, and averages over them. This is the prefered method. However, if there are only a few samples per cell type (in average below 10 samples per type) we recommend to mix samples using jitter. For both methods we provide functions within the DTD package.

### Many samples --> directly

The `mix.samples` function needs the following arguments:

- gene.mat: numeric matrix, here `train.mat`
- pheno: named list of strings, here `indicator.list`
- included.in.X: list of strings, here include.in.X
- nSamples: integer, how many in-silicio mixtures should be generated. 
- nPerMixture: integer, how many cells should be included in each mixture
- verbose: boolean, should output be printed. 

```{r}
  indicator.train <- indicator.list[names(indicator.list) %in% colnames(train.mat)]
  training.data <- mix.samples(gene.mat = train.mat,
                               pheno = indicator.train,
                               included.in.X = include.in.X, 
                               nSamples = nSamples, 
                               nPerMixture = 100, 
                               verbose = F)
  str(training.data)
```
Remark that all types are included in the mixtures, but only the distributions of the cell within the X matrix are reported in the quantities matrix. 
With the same function we generate a test set. Notice that a sample is only used once, either in the reference matrix X, in the test set or in the training set. 

```{r}
  indicator.test <- indicator.list[names(indicator.list) %in% colnames(test.mat)]
  test.data <- mix.samples(gene.mat = test.mat,
                           pheno = indicator.test,
                           included.in.X = include.in.X, 
                           nSamples = nSamples, 
                           nPerMixture = 100, 
                           verbose = F)
```

### Less samples --> with jitter
The `mix.samples.jitter` function needs a bit more preliminary work. 
It takes the following arguments: 

- special.names: list of strings. Cell types included in the special.names list will occur with higher quantities in the mixtures 
- sample.names: list of strings. Cell types included in the sample.names list will occur with lower quantities in the mixtures

The idea behind splitting all samples in the data set into `special.names` and `sample.names` is: 
In a tumor tissue malignant cells make up ~75% of all cells. In contrast to that, certain immune cells (e.g. a macrophage subtype) make up only ~5 % of all cells. 
In the training set imbalanced quantities should be reflected. 

- nSamples: integer, how many in-silicio mixtures should be generated. 
- datamatrix: numeric matrix, here `train.mat`
- pheno: named list of strings, here `indicator.list`
- verbose: boolean,  should output be printed. 
- singleSpecial: boolean, if `FALSE`  all `special.samples` will be included in all mixtures, or if `TRUE`  only one `special.sample` will be included per mixture. This option should be used if `special.samples` represent different tumor types. 
- add_jitter: boolean, should the mixtures be multiplied with jitter. 
- chosen.mean: numeric, mean of jitter
- chosen.sd: numeric, standard deviation of jitter
- min.amount.samples: integer, how many samples have to be present such that it averages over them, instad of taking only 1. 
- included.in.X: list of strings, here include.in.X

```{r}
  # Here, we set "Type1" to be special:
  special.samples <- c("Type1")
  # and all other to be normal: 
  all.samples <- unique(indicator.list)
  sample.names <- all.samples[- which(all.samples %in% special.samples)]
  
  # reduce indicator list to those samples included in training: 
  indicator.list <- indicator.list[names(indicator.list) %in% colnames(train.mat)]
  
  training.data.jitter <- mix.samples.jitter(sample.names = sample.names,
                                             special.samples = special.samples, 
                                             nSamples = nSamples, 
                                             datamatrix = train.mat, 
                                             pheno = indicator.list, 
                                             verbose = F, 
                                             add_jitter = T, 
                                             included.in.X = include.in.X)
```

## Train g vector

In the optimizing procedure we search for a vector g, which minimizes our loss function L: 
\begin{equation}
  L = - \sum_{j=1}^g cor(C_{j,.}, \widehat{C_{j,.}} (g))
\end{equation}
This optimization is done iteratively by gradient descent, using an implementation of 'FISTA' (Fast iterative shrinkage thresholding algorithm) @Beck2009.

Our FISTA implementation takes the following arguments: 
- tweak_vec: numeric vector, with which the minimization starts. 
- maxit: integer, maximum number of iterations. 
- learning.rate: float, initial step size while learning. During the algorithm it may in or decreased. 
- F.GRAD.FUN: function with one parameter: a vector with same length as tweak_vec, and one return value with the same length. For a given vector, it returns the gradient of the loss function. 
- EVAL.FUN: function with one parameter: a vector with same length as tweak_vec, and a float as return value. For a given vector, it returns the value of the loss function. 

WHY NEED OF WRAPPER
```{r}
   # wrapper for gradient:
   DTD.grad.wrapper <- function(tweak){
      X <- X.matrix
      Y <- training.data$mixtures
      C <- training.data$quantities
      grad <- Trace.H.gradient(X = X, Y = Y, C = C, tweak = tweak)
      return(grad)
   }
  # wrapper for evaluation:
  DTD.evCor.wrapper <- function(tweak){
      X <- X.matrix
      Y <- training.data$mixtures
      C <- training.data$quantities
      loss <- evaluate_cor(X = X, Y = Y, C = C, tweak = tweak)
      return(loss)
  }
```

Now, the optimization procedure can be started: 

```{r}
  start_tweak <- rep(1, nrow(X.matrix))
  catch <- descent_generalized_fista(tweak_vec = start_tweak,
                                     F.GRAD.FUN = DTD.grad.wrapper,
                                     ST.FUN = soft_thresholding,
                                     FACTOR.FUN = nesterov_faktor,
                                     EVAL.FUN = DTD.evCor.wrapper,
                                     line_search_speed = 2,
                                     maxit = maxit,
                                     save_all_tweaks = T, 
                                     verbose = F)
  str(catch)
```
The output of the `descent_generalized_fista` algorithm is a list. It returns the `tweak_vec` after the last iterations, and a convergence vector. Within the convergence vector there are the evaluations of the `EVAL.FUN` in every step.  

## Visualize results
### Visualization of learn curve
  During the training step, the algorithm finds a g-vector which minimzes the Loss-function. In order to visualize the training curve, the function `ggplot_correlation` can be used. 
  Additionally to the output of `descent_generalized_fista` a test set and the X.matrix can be provided.  
```{r, fig.width=5}
  print(ggplot_correlation(fista.output = catch, 
                           test.set = test.data, 
                           X.matrix = X.matrix, 
                           main = "DTD Vignette"))
```

The trained model needs to be evaluated on the test set.  Therefore the function `ggplot_true_vs_esti` can be used. As input it takes the cell estimations of the DTD model on the test set, and the true cell compositions of the test set. In addition a `color.indi` vector can be provided
```{r, fig.width=7}
  test.estimations <- est.cs(X = X.matrix, 
                             Y = test.data$mixtures, 
                             gamma.vec = catch$Tweak
                            )
 print(ggplot_true_vs_esti(estimatedC = test.estimations,
                           trueC = test.data$quantities, 
                           norm.columnwise = FALSE)
       )
```






# References
