<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />

<meta name="viewport" content="width=device-width, initial-scale=1">

<meta name="author" content="Marian Schön" />

<meta name="date" content="2018-08-07" />

<title>Loss-function learning for digital tissue deconvolution</title>



<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>



<link href="data:text/css;charset=utf-8,body%20%7B%0Abackground%2Dcolor%3A%20%23fff%3B%0Amargin%3A%201em%20auto%3B%0Amax%2Dwidth%3A%20700px%3B%0Aoverflow%3A%20visible%3B%0Apadding%2Dleft%3A%202em%3B%0Apadding%2Dright%3A%202em%3B%0Afont%2Dfamily%3A%20%22Open%20Sans%22%2C%20%22Helvetica%20Neue%22%2C%20Helvetica%2C%20Arial%2C%20sans%2Dserif%3B%0Afont%2Dsize%3A%2014px%3B%0Aline%2Dheight%3A%201%2E35%3B%0A%7D%0A%23header%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0A%23TOC%20%7B%0Aclear%3A%20both%3B%0Amargin%3A%200%200%2010px%2010px%3B%0Apadding%3A%204px%3B%0Awidth%3A%20400px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Aborder%2Dradius%3A%205px%3B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Afont%2Dsize%3A%2013px%3B%0Aline%2Dheight%3A%201%2E3%3B%0A%7D%0A%23TOC%20%2Etoctitle%20%7B%0Afont%2Dweight%3A%20bold%3B%0Afont%2Dsize%3A%2015px%3B%0Amargin%2Dleft%3A%205px%3B%0A%7D%0A%23TOC%20ul%20%7B%0Apadding%2Dleft%3A%2040px%3B%0Amargin%2Dleft%3A%20%2D1%2E5em%3B%0Amargin%2Dtop%3A%205px%3B%0Amargin%2Dbottom%3A%205px%3B%0A%7D%0A%23TOC%20ul%20ul%20%7B%0Amargin%2Dleft%3A%20%2D2em%3B%0A%7D%0A%23TOC%20li%20%7B%0Aline%2Dheight%3A%2016px%3B%0A%7D%0Atable%20%7B%0Amargin%3A%201em%20auto%3B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dcolor%3A%20%23DDDDDD%3B%0Aborder%2Dstyle%3A%20outset%3B%0Aborder%2Dcollapse%3A%20collapse%3B%0A%7D%0Atable%20th%20%7B%0Aborder%2Dwidth%3A%202px%3B%0Apadding%3A%205px%3B%0Aborder%2Dstyle%3A%20inset%3B%0A%7D%0Atable%20td%20%7B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dstyle%3A%20inset%3B%0Aline%2Dheight%3A%2018px%3B%0Apadding%3A%205px%205px%3B%0A%7D%0Atable%2C%20table%20th%2C%20table%20td%20%7B%0Aborder%2Dleft%2Dstyle%3A%20none%3B%0Aborder%2Dright%2Dstyle%3A%20none%3B%0A%7D%0Atable%20thead%2C%20table%20tr%2Eeven%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Ap%20%7B%0Amargin%3A%200%2E5em%200%3B%0A%7D%0Ablockquote%20%7B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Apadding%3A%200%2E25em%200%2E75em%3B%0A%7D%0Ahr%20%7B%0Aborder%2Dstyle%3A%20solid%3B%0Aborder%3A%20none%3B%0Aborder%2Dtop%3A%201px%20solid%20%23777%3B%0Amargin%3A%2028px%200%3B%0A%7D%0Adl%20%7B%0Amargin%2Dleft%3A%200%3B%0A%7D%0Adl%20dd%20%7B%0Amargin%2Dbottom%3A%2013px%3B%0Amargin%2Dleft%3A%2013px%3B%0A%7D%0Adl%20dt%20%7B%0Afont%2Dweight%3A%20bold%3B%0A%7D%0Aul%20%7B%0Amargin%2Dtop%3A%200%3B%0A%7D%0Aul%20li%20%7B%0Alist%2Dstyle%3A%20circle%20outside%3B%0A%7D%0Aul%20ul%20%7B%0Amargin%2Dbottom%3A%200%3B%0A%7D%0Apre%2C%20code%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0Aborder%2Dradius%3A%203px%3B%0Acolor%3A%20%23333%3B%0Awhite%2Dspace%3A%20pre%2Dwrap%3B%20%0A%7D%0Apre%20%7B%0Aborder%2Dradius%3A%203px%3B%0Amargin%3A%205px%200px%2010px%200px%3B%0Apadding%3A%2010px%3B%0A%7D%0Apre%3Anot%28%5Bclass%5D%29%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Acode%20%7B%0Afont%2Dfamily%3A%20Consolas%2C%20Monaco%2C%20%27Courier%20New%27%2C%20monospace%3B%0Afont%2Dsize%3A%2085%25%3B%0A%7D%0Ap%20%3E%20code%2C%20li%20%3E%20code%20%7B%0Apadding%3A%202px%200px%3B%0A%7D%0Adiv%2Efigure%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0Aimg%20%7B%0Abackground%2Dcolor%3A%20%23FFFFFF%3B%0Apadding%3A%202px%3B%0Aborder%3A%201px%20solid%20%23DDDDDD%3B%0Aborder%2Dradius%3A%203px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Amargin%3A%200%205px%3B%0A%7D%0Ah1%20%7B%0Amargin%2Dtop%3A%200%3B%0Afont%2Dsize%3A%2035px%3B%0Aline%2Dheight%3A%2040px%3B%0A%7D%0Ah2%20%7B%0Aborder%2Dbottom%3A%204px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Apadding%2Dbottom%3A%202px%3B%0Afont%2Dsize%3A%20145%25%3B%0A%7D%0Ah3%20%7B%0Aborder%2Dbottom%3A%202px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Afont%2Dsize%3A%20120%25%3B%0A%7D%0Ah4%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23f7f7f7%3B%0Amargin%2Dleft%3A%208px%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Ah5%2C%20h6%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23ccc%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Aa%20%7B%0Acolor%3A%20%230033dd%3B%0Atext%2Ddecoration%3A%20none%3B%0A%7D%0Aa%3Ahover%20%7B%0Acolor%3A%20%236666ff%3B%20%7D%0Aa%3Avisited%20%7B%0Acolor%3A%20%23800080%3B%20%7D%0Aa%3Avisited%3Ahover%20%7B%0Acolor%3A%20%23BB00BB%3B%20%7D%0Aa%5Bhref%5E%3D%22http%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0Aa%5Bhref%5E%3D%22https%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0A%0Acode%20%3E%20span%2Ekw%20%7B%20color%3A%20%23555%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Edt%20%7B%20color%3A%20%23902000%3B%20%7D%20%0Acode%20%3E%20span%2Edv%20%7B%20color%3A%20%2340a070%3B%20%7D%20%0Acode%20%3E%20span%2Ebn%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Efl%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Ech%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Est%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Eco%20%7B%20color%3A%20%23888888%3B%20font%2Dstyle%3A%20italic%3B%20%7D%20%0Acode%20%3E%20span%2Eot%20%7B%20color%3A%20%23007020%3B%20%7D%20%0Acode%20%3E%20span%2Eal%20%7B%20color%3A%20%23ff0000%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Efu%20%7B%20color%3A%20%23900%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%20code%20%3E%20span%2Eer%20%7B%20color%3A%20%23a61717%3B%20background%2Dcolor%3A%20%23e3d2d2%3B%20%7D%20%0A" rel="stylesheet" type="text/css" />

</head>

<body>




<h1 class="title toc-ignore">Loss-function learning for digital tissue deconvolution</h1>
<h4 class="author"><em>Marian Schön</em></h4>
<h4 class="date"><em>2018-08-07</em></h4>


<div id="TOC">
<ul>
<li><a href="#what-is-dtd">What is DTD?</a></li>
<li><a href="#how-to-use">How to use?</a><ul>
<li><a href="#data-generation">Data generation</a></li>
<li><a href="#data-processing">Data processing</a></li>
<li><a href="#reference-matrix-x">Reference matrix X</a></li>
<li><a href="#mixing-training-and-test-set">Mixing training and test set</a><ul>
<li><a href="#many-samples-directly">Many samples –&gt; directly</a></li>
<li><a href="#less-samples-with-jitter">Less samples –&gt; with jitter</a></li>
</ul></li>
<li><a href="#train-g-vector">Train g vector</a></li>
</ul></li>
<li><a href="#references">References</a></li>
</ul>
</div>

<div id="what-is-dtd" class="section level1">
<h1>What is DTD?</h1>
<p>The gene expression profile of a tissue averages the expression profiles of all cells in this tissue. Digital tissue deconvolution (DTD) addresses the following inverse problem: Given the expression profile y of a tissue, what is the cellular composition c of that tissue? The theory and mathematical background of a DTD model that uses loss-function learning has been published by <span class="citation">Görtler et al. (2018)</span>. With this package we provide all necessary R functions and routines to train and use a loss-function learning digital tissue deconvolution model.</p>
Let’s start with the notation used in the article. The reference matrix is denoted as X. Every column <span class="math inline">\(X_{.,k}\)</span> is a cellular reference profile. The expression matrix of bulk profiles is named Y. Every column <span class="math inline">\(Y_{.,k}\)</span> is a mixtures of cells, for which the quantities of the cells in X should be estimated. The standard decovnolution formula is given by
<span class="math display">\[\begin{equation}
  arg~ min_c ~|| Y_{.,k} - Xc||
\end{equation}\]</span>
<span class="citation">Görtler et al. (2018)</span> improve this formula by introducing a vector g
<span class="math display">\[\begin{equation}
  arg~ min_c ~|| diag(g) (Y_{.,k} - Xc)||
\end{equation}\]</span>
Every entry <span class="math inline">\(g_i\)</span> of g holds the information how important gene i is for the deconvolution process. The underlying idea of loss-function learning DTD is to gain the vector g by minimizing a loss function L on a training set.
<span class="math display">\[\begin{equation}
  L = - \sum_{j=1}^g cor(C_{j,.}, \widehat{C_{j,.}} (g))
\end{equation}\]</span>
<p>The training set consists of a matrix Y with bulk profiles, for which the quantities of the cells in X should be estimated. Additionally there is a matrix C. In the composition or quantity matrix C every column <span class="math inline">\(C_{.,k}\)</span> holds the distribution of the reference cells X in the bulk profile <span class="math inline">\(Y_{.,k}\)</span>. For the loss function L the correlation between the known quantities <span class="math inline">\(C_{j,.}\)</span> and the estimated quantities <span class="math inline">\(\widehat{C_{j,.}}(g)\)</span> is calculated per reference profile j.</p>
<p>In the package DTD we provide functions to generate a trainings and test set, and a FISTA implementation to minimize the loss function iteratively.</p>
</div>
<div id="how-to-use" class="section level1">
<h1>How to use?</h1>
<p>In the following examples, we demonstrate how data has to look like, in order to be used for loss-function learning digital tissue deconvolution. After that, we give examples on how to process the data, how to generate a test and training set, how to train the g vector, and finally, how to visualize the result. First of all, load the library:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">  <span class="kw">library</span>(DTD)</code></pre></div>
<div id="data-generation" class="section level2">
<h2>Data generation</h2>
<p>The DTD package needs expression measurements of sorted cells to train a g-vector. We did not include any data in the DTD package. In order to demonstrate all functions, and to show users how the data needs to be processed, we included a <code>generate.random.data</code> function. Basically, this function has 3 key arguments:</p>
<ul>
<li>nTypes: integer, how many different types should be included in the data set.</li>
<li>nSamples.perType: integer, ow many samples should be generated per type.</li>
<li>nFeatures: integer, how many features should be included.</li>
</ul>
<p>In the following we generate data consisting of 5 different cell types, with 100 features. For each cell type we generate 5 samples.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">  number.types &lt;-<span class="st"> </span><span class="dv">5</span>
  number.samples.per.type &lt;-<span class="st"> </span><span class="dv">10</span>
  random.data &lt;-<span class="st"> </span><span class="kw">generate.random.data</span>(<span class="dt">nTypes =</span> number.types, 
                                      <span class="dt">nSamples.perType =</span> number.samples.per.type, 
                                      <span class="dt">nFeatures =</span> <span class="dv">100</span>)
  <span class="kw">print</span>(random.data[<span class="dv">1</span><span class="op">:</span><span class="dv">5</span>, <span class="dv">1</span><span class="op">:</span><span class="dv">5</span>])
<span class="co">#&gt;       Cell1.Type1 Cell2.Type1 Cell3.Type1 Cell4.Type1 Cell5.Type1</span>
<span class="co">#&gt; gene1   13.119657   62.552596   19.428990   20.889915    3.478718</span>
<span class="co">#&gt; gene2   15.050439    0.188882   40.559117    4.455845   45.359011</span>
<span class="co">#&gt; gene3    4.416009   15.154149    6.249073   15.372022   35.850996</span>
<span class="co">#&gt; gene4   15.363244    7.830015   13.380539   40.388769   27.511493</span>
<span class="co">#&gt; gene5   26.875765   13.467288   56.906897    3.432228   23.596134</span>
  
  <span class="co"># for further exemplary visualization </span>
  example.index &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">12</span>, <span class="dv">23</span>, <span class="dv">34</span>, <span class="dv">44</span>)</code></pre></div>
<p>The object <code>random.data</code> is a numeric matrix with 100 rows (features), and 51 columns (samples). Notice that the colnames of <code>random.data</code> indicate the type of cell:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">  <span class="kw">print</span>(<span class="kw">colnames</span>(random.data)[example.index])
<span class="co">#&gt; [1] &quot;Cell1.Type1&quot;  &quot;Cell12.Type2&quot; &quot;Cell23.Type3&quot; &quot;Cell34.Type4&quot;</span>
<span class="co">#&gt; [5] &quot;Cell44.Type5&quot;</span></code></pre></div>
<p>The expression matrix <code>random.data</code> now looks similar to expression measurements published by <span class="citation">Tirosh et al. (2016)</span> OR DO I HAVE ANY OTHER EXAMPLE.</p>
</div>
<div id="data-processing" class="section level2">
<h2>Data processing</h2>
<p>The first step in processing the raw expression matrix is to undo log transformation. This is necessary because our DTD algorithm works on an additive scale, not a multiplicative.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">  <span class="cf">if</span>(<span class="kw">max</span>(random.data) <span class="op">&lt;</span><span class="st"> </span><span class="dv">25</span>){ 
    random.data &lt;-<span class="st"> </span><span class="dv">2</span><span class="op">^</span>random.data
  }</code></pre></div>
<p>Next, we scale every sample of the data set to a common number of counts. This brings all samples to the same scale, and makes them comparable. In the DTD package the function <code>normalizeToCount</code> can be used:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">  <span class="co"># In random.data the number of counts differs over all samples: </span>
  <span class="kw">apply</span>(random.data, <span class="dv">2</span>, sum)[example.index]
<span class="co">#&gt;  Cell1.Type1 Cell12.Type2 Cell23.Type3 Cell34.Type4 Cell44.Type5 </span>
<span class="co">#&gt;     1638.849     4074.394     5015.088     3025.548     3028.510</span>
  normalized.data &lt;-<span class="st"> </span><span class="kw">normalizeToCount</span>(random.data)
  <span class="co"># In normalized.data all samples share the same number of counts: </span>
  <span class="kw">apply</span>(normalized.data, <span class="dv">2</span>, sum)[example.index]
<span class="co">#&gt;  Cell1.Type1 Cell12.Type2 Cell23.Type3 Cell34.Type4 Cell44.Type5 </span>
<span class="co">#&gt;        1e+06        1e+06        1e+06        1e+06        1e+06</span></code></pre></div>
<p>In addition to the normalized data matrix the DTD algorithm needs a <code>indicator.list</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> indicator.list &lt;-<span class="st"> </span><span class="kw">gsub</span>(<span class="st">&quot;^Cell([0-9])*.&quot;</span>, <span class="st">&quot;&quot;</span>, <span class="kw">colnames</span>(normalized.data))
 <span class="kw">names</span>(indicator.list) &lt;-<span class="st"> </span><span class="kw">colnames</span>(normalized.data)
 <span class="kw">print</span>(indicator.list[example.index])
<span class="co">#&gt;  Cell1.Type1 Cell12.Type2 Cell23.Type3 Cell34.Type4 Cell44.Type5 </span>
<span class="co">#&gt;      &quot;Type1&quot;      &quot;Type2&quot;      &quot;Type3&quot;      &quot;Type4&quot;      &quot;Type5&quot;</span></code></pre></div>
<p><code>indicator.list</code> needs to be a named list. Each entry assigns the cell type (as value of the list) to every sample (names of the list) in the <code>random.data</code>.</p>
</div>
<div id="reference-matrix-x" class="section level2">
<h2>Reference matrix X</h2>
<p>Next, we select the reference matrix X. In our data set there are 5 different cell types. In this example we do not distinguish between all of them. The samples we want to deconvolute are:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">  include.in.X &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;Type2&quot;</span>, <span class="st">&quot;Type3&quot;</span>, <span class="st">&quot;Type4&quot;</span>, <span class="st">&quot;Type5&quot;</span>)</code></pre></div>
<p>For each of these types we need a reference profile x, which will be gathered together and become the reference matrix X:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">  X.matrix &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="ot">NA</span>, <span class="dt">nrow=</span><span class="kw">nrow</span>(normalized.data), <span class="dt">ncol=</span><span class="kw">length</span>(include.in.X))
  <span class="kw">colnames</span>(X.matrix) &lt;-<span class="st"> </span>include.in.X
  <span class="kw">rownames</span>(X.matrix) &lt;-<span class="st"> </span><span class="kw">rownames</span>(normalized.data)</code></pre></div>
<p>For each cell type its reference profil will be calculated as the average over a fraction of all samples in the whole data set:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">  percentage.of.all.cells &lt;-<span class="st"> </span><span class="fl">0.2</span>
  samples.to.remove &lt;-<span class="st"> </span><span class="kw">c</span>()
  <span class="cf">for</span>(l.type <span class="cf">in</span> include.in.X){
    <span class="co"># get sample names of all cells of type &quot;l.type&quot; </span>
    all.of.type &lt;-<span class="st"> </span><span class="kw">names</span>(indicator.list)[<span class="kw">which</span>(indicator.list <span class="op">==</span><span class="st"> </span>l.type)]
    
    <span class="co"># randomly sample some cells</span>
    chosen.for.X &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="dt">x =</span> all.of.type,
                           <span class="dt">size =</span> <span class="kw">ceiling</span>(<span class="kw">length</span>(all.of.type) <span class="op">*</span><span class="st"> </span>percentage.of.all.cells),
                           <span class="dt">replace =</span> <span class="ot">FALSE</span>)
    
    <span class="co"># Add those cells which will be included in X to the list of samples.to.remove </span>
    samples.to.remove &lt;-<span class="st"> </span><span class="kw">c</span>(samples.to.remove, chosen.for.X)

    <span class="co"># for each gene average over the selected </span>
    average &lt;-<span class="st"> </span><span class="kw">rowSums</span>(normalized.data[, chosen.for.X, <span class="dt">drop =</span> F])
    X.matrix[, l.type] &lt;-<span class="st"> </span>average
 }</code></pre></div>
<p>Notice that every sample which has been used in the reference matrix X must not be included in the training or test set! In order to keep track of samples which must not be used furthermore we introduced the variable <code>samples.to.remove</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">  train.mat &lt;-<span class="st"> </span>random.data[, <span class="op">-</span><span class="kw">which</span>(<span class="kw">colnames</span>(random.data) <span class="op">%in%</span><span class="st"> </span>samples.to.remove)]</code></pre></div>
</div>
<div id="mixing-training-and-test-set" class="section level2">
<h2>Mixing training and test set</h2>
<p>The loss-function learning DTD algorithm trains a g-vector on a trainig set. Basically, the training set is a list of two matrices.</p>
<ul>
<li>Y, or mixtures matrix. Y has as many rows (=features) as <code>X.matrix</code> or <code>normalized.data</code>. Every column y of Y is a mixture of the cells in the data set.</li>
<li>C, or quantities matrix. C has as many rows as there are cells in <code>X.matrix</code>. Every column of C holds the distribution of the cells in each mixture of Y.</li>
</ul>
<p>In this package we provide two methods to generate the training set. One method randomly samples many cells of the complete data set, and averages over them. This is the prefered method. However, if there are only a few samples per cell type (in average below 10 samples per type) we recommend to mix samples using jitter. For both methods we provide functions within the DTD package.</p>
<div id="many-samples-directly" class="section level3">
<h3>Many samples –&gt; directly</h3>
<p>The <code>mix.samples</code> function needs the following arguments:</p>
<ul>
<li>gene.mat: numeric matrix, here <code>train.mat</code></li>
<li>pheno: named list of strings, here <code>indicator.list</code></li>
<li>included.in.X: list of strings, here include.in.X</li>
<li>nSamples: integer, how many in-silicio mixtures should be generated.</li>
<li>nPerMixture: integer, how many cells should be included in each mixture</li>
<li>verbose: boolean, should output be printed.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">  training.data &lt;-<span class="st"> </span><span class="kw">mix.samples</span>(<span class="dt">gene.mat =</span> train.mat,
                               <span class="dt">pheno =</span> indicator.list,
                               <span class="dt">included.in.X =</span> include.in.X, 
                               <span class="dt">nSamples =</span> nSamples, 
                               <span class="dt">nPerMixture =</span> <span class="dv">5</span>, 
                               <span class="dt">verbose =</span> F)
  <span class="kw">str</span>(training.data)
<span class="co">#&gt; List of 2</span>
<span class="co">#&gt;  $ mixtures  : num [1:100, 1:5] 14373 7235 14428 10561 12639 ...</span>
<span class="co">#&gt;   ..- attr(*, &quot;dimnames&quot;)=List of 2</span>
<span class="co">#&gt;   .. ..$ : chr [1:100] &quot;gene1&quot; &quot;gene2&quot; &quot;gene3&quot; &quot;gene4&quot; ...</span>
<span class="co">#&gt;   .. ..$ : chr [1:5] &quot;mixtures1&quot; &quot;mixtures2&quot; &quot;mixtures3&quot; &quot;mixtures4&quot; ...</span>
<span class="co">#&gt;  $ quantities: num [1:4, 1:5] 0.2 0.4 0.2 0 0.2 0.4 0 0.2 0.4 0.2 ...</span>
<span class="co">#&gt;   ..- attr(*, &quot;dimnames&quot;)=List of 2</span>
<span class="co">#&gt;   .. ..$ : chr [1:4] &quot;Type2&quot; &quot;Type3&quot; &quot;Type4&quot; &quot;Type5&quot;</span>
<span class="co">#&gt;   .. ..$ : chr [1:5] &quot;mixtures1&quot; &quot;mixtures2&quot; &quot;mixtures3&quot; &quot;mixtures4&quot; ...</span></code></pre></div>
<p>Remark that all types are included in the mixtures, but only the distributions of the cell within the X matrix are reported in the quantities matrix.</p>
</div>
<div id="less-samples-with-jitter" class="section level3">
<h3>Less samples –&gt; with jitter</h3>
<p>The <code>mix.samples.jitter</code> function needs a bit more preliminary work. It takes the following arguments:</p>
<ul>
<li>special.names: list of strings. Cell types included in the special.names list will occur with higher quantities in the mixtures</li>
<li>sample.names: list of strings. Cell types included in the sample.names list will occur with lower quantities in the mixtures</li>
</ul>
<p>The idea behind splitting all samples in the data set into <code>special.names</code> and <code>sample.names</code> is: In a tumor tissue malignant cells make up ~75% of all cells. In contrast to that, certain immune cells (e.g. a macrophage subtype) make up only ~5 % of all cells. In the training set imbalanced quantities should be reflected.</p>
<ul>
<li>nSamples: integer, how many in-silicio mixtures should be generated.</li>
<li>datamatrix: numeric matrix, here <code>train.mat</code></li>
<li>pheno: named list of strings, here <code>indicator.list</code></li>
<li>verbose: boolean, should output be printed.</li>
<li>singleSpecial: boolean, if <code>FALSE</code> all <code>special.samples</code> will be included in all mixtures, or if <code>TRUE</code> only one <code>special.sample</code> will be included per mixture. This option should be used if <code>special.samples</code> represent different tumor types.</li>
<li>add_jitter: boolean, should the mixtures be multiplied with jitter.</li>
<li>chosen.mean: numeric, mean of jitter</li>
<li>chosen.sd: numeric, standard deviation of jitter</li>
<li>min.amount.samples: integer, how many samples have to be present such that it averages over them, instad of taking only 1.</li>
<li>included.in.X: list of strings, here include.in.X</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">  <span class="co"># Here, we set &quot;Type1&quot; to be special:</span>
  special.samples &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;Type1&quot;</span>)
  <span class="co"># and all other to be normal: </span>
  all.samples &lt;-<span class="st"> </span><span class="kw">unique</span>(indicator.list)
  sample.names &lt;-<span class="st"> </span>all.samples[<span class="op">-</span><span class="st"> </span><span class="kw">which</span>(all.samples <span class="op">%in%</span><span class="st"> </span>special.samples)]
  
  <span class="co"># reduce indicator list to those samples included in training: </span>
  indicator.list &lt;-<span class="st"> </span>indicator.list[<span class="kw">names</span>(indicator.list) <span class="op">%in%</span><span class="st"> </span><span class="kw">colnames</span>(train.mat)]
  
  training.data.jitter &lt;-<span class="st"> </span><span class="kw">mix.samples.jitter</span>(<span class="dt">sample.names =</span> sample.names,
                                             <span class="dt">special.samples =</span> special.samples, 
                                             <span class="dt">nSamples =</span> nSamples, 
                                             <span class="dt">datamatrix =</span> train.mat, 
                                             <span class="dt">pheno =</span> indicator.list, 
                                             <span class="dt">verbose =</span> F, 
                                             <span class="dt">add_jitter =</span> T, 
                                             <span class="dt">included.in.X =</span> include.in.X)</code></pre></div>
</div>
</div>
<div id="train-g-vector" class="section level2">
<h2>Train g vector</h2>
<p>Now we generated a training set, and are nearly set to start the optimizing procedure. <sub><del>In this package we implemented a adjusted FISTA algorithm to minimize our Loss-function. FISTA (fast iterative shrinkage thresholding algorithm) is a iterative proximal gradient method with Nesterov acceleration. Basically, the FISTA algorithm can be described as a extrapolation/correction/nesterov step after a proximal gradient descen step. In the loss-function learning DTD context the computational expensive part is the calculation of the gradient.</del></sub></p>
<p>We provide a function with the following arguments:</p>
<ul>
<li>tweak_vec: numeric vector, with which the minimization starts.</li>
<li>maxit: integer, maximum number of iterations.</li>
<li>learning.rate: float, initial step size while learning. During the algorithm it may in or decreased.</li>
<li>F.GRAD.FUN: function with one parameter: a vector with same length as tweak_vec, and one return value with the same length. For a given vector, it returns the gradient of the loss function.</li>
<li>EVAL.FUN: function with one parameter: a vector with same length as tweak_vec, and a float as return value. For a given vector, it returns the value of the loss function.</li>
</ul>
<p>Both functions take only one list as input argument, which is the <code>tweak_vec</code>. If the gradient function takes more than one argument, a wrapper function is needed:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">  DTD.grad.wrapper &lt;-<span class="st"> </span><span class="cf">function</span>(tweak){
      X &lt;-<span class="st"> </span>X.matrix
      Y &lt;-<span class="st"> </span>training.data<span class="op">$</span>mixtures
      C &lt;-<span class="st"> </span>training.data<span class="op">$</span>quantities
      grad &lt;-<span class="st"> </span><span class="kw">Trace.H.gradient</span>(<span class="dt">X =</span> X, <span class="dt">Y =</span> Y, <span class="dt">C =</span> C, <span class="dt">gamma.vec =</span> tweak)
      <span class="kw">return</span>(grad)
  }
  DTD.evCor.wrapper &lt;-<span class="st"> </span><span class="cf">function</span>(tweak){
      X &lt;-<span class="st"> </span>X.matrix
      Y &lt;-<span class="st"> </span>training.data<span class="op">$</span>mixtures
      C &lt;-<span class="st"> </span>training.data<span class="op">$</span>quantities
      loss &lt;-<span class="st"> </span><span class="kw">evaluate_cor</span>(<span class="dt">X =</span> X, <span class="dt">Y =</span> Y, <span class="dt">C =</span> C, <span class="dt">tweak =</span> tweak)
  }</code></pre></div>
<p>Now, the optimization procedure can be started:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">  start_tweak &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="dv">1</span>, <span class="kw">nrow</span>(X.matrix))
  catch &lt;-<span class="st"> </span><span class="kw">descent_generalized_fista</span>(<span class="dt">tweak_vec =</span> start_tweak,
                                      <span class="dt">F.GRAD.FUN =</span> DTD.grad.wrapper,
                                      <span class="dt">ST.FUN =</span> soft_thresholding,
                                      <span class="dt">FACTOR.FUN =</span> nesterov_faktor,
                                      <span class="dt">EVAL.FUN =</span> DTD.evCor.wrapper,
                                      <span class="dt">line_search_speed =</span> <span class="dv">2</span>,
                                      <span class="dt">maxit =</span> maxit,
                                      <span class="dt">save_all_tweaks =</span> T, 
                                      <span class="dt">verbose =</span> F)
  <span class="kw">str</span>(catch)
<span class="co">#&gt; List of 3</span>
<span class="co">#&gt;  $ Tweak      : num [1:100] 0.955 1.02 0.988 1.049 1.057 ...</span>
<span class="co">#&gt;  $ Convergence: num [1:2] 1.32 1.14</span>
<span class="co">#&gt;  $ History    : num [1:100, 1:2] 1 1 1 1 1 1 1 1 1 1 ...</span></code></pre></div>
<p>The output of the <code>descent_generalized_fista</code> algorithm is a list. It returns the <code>tweak_vec</code> after the last iterations, and a convergence vector. Within the convergence vector there are stored the evaluations of the <code>EVAL.FUN</code> in every step. ## Visualize results</p>
</div>
</div>
<div id="references" class="section level1 unnumbered">
<h1>References</h1>
<div id="refs" class="references">
<div id="ref-Goertler2018">
<p>Görtler, Franziska, Stefan Solbrig, Tilo Wettig, Peter J. Oefner, Rainer Spang, and Michael Altenbuchinger. 2018. <em>Research in Computational Molecular Biology: 22nd Annual International Conference, Recomb 2018, Paris, France, April 21-24, 2018, Proceedings (Lecture Notes in Computer Science)</em>. Springer.</p>
</div>
<div id="ref-Tirosh2016">
<p>Tirosh, I., B. Izar, S. M. Prakadan, M. H. Wadsworth, D. Treacy, J. J. Trombetta, A. Rotem, et al. 2016. “Dissecting the Multicellular Ecosystem of Metastatic Melanoma by Single-Cell RNA-Seq.” <em>Science</em> 352 (6282). American Association for the Advancement of Science (AAAS): 189–96. doi:<a href="https://doi.org/10.1126/science.aad0501">10.1126/science.aad0501</a>.</p>
</div>
</div>
</div>



<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
